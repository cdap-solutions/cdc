<?xml version="1.0" encoding="UTF-8"?>
<!--
  ~ Copyright Â© 2016 Cask Data, Inc.
  ~
  ~ Licensed under the Apache License, Version 2.0 (the "License"); you may not
  ~ use this file except in compliance with the License. You may obtain a copy of
  ~ the License at
  ~
  ~ http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
  ~ WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
  ~ License for the specific language governing permissions and limitations under
  ~ the License.
  -->
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>

  <groupId>co.cask.hydrator</groupId>
  <artifactId>sql-server-streaming-source</artifactId>
  <version>1.0.0-SNAPSHOT</version>
  <packaging>jar</packaging>

  <name>SQL Server Streaming Source</name>

  <properties>
    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    <spark.version>1.6.1</spark.version>
    <cdap.version>4.2.0-SNAPSHOT</cdap.version>
    <hydrator.plugins.version>1.6.0</hydrator.plugins.version>
    <!-- properties for script build step that creates the config files for the artifacts -->
    <widgets.dir>widgets</widgets.dir>
    <docs.dir>docs</docs.dir>
    <app.parents>system:cdap-data-streams[4.1.0,4.3.0)</app.parents>
    <!-- this is here because project.basedir evaluates to null in the script build step -->
    <main.basedir>${project.basedir}</main.basedir>
  </properties>

  <repositories>
    <repository>
      <id>sonatype</id>
      <url>https://oss.sonatype.org/content/groups/public</url>
    </repository>
    <repository>
      <id>sonatype-snapshots</id>
      <url>https://oss.sonatype.org/content/repositories/snapshots</url>
    </repository>
  </repositories>

  <dependencies>
    <dependency>
      <groupId>co.cask.cdap</groupId>
      <artifactId>cdap-etl-api</artifactId>
      <version>${cdap.version}</version>
    </dependency>
    <dependency>
      <groupId>co.cask.cdap</groupId>
      <artifactId>cdap-etl-api-spark</artifactId>
      <version>${cdap.version}</version>
    </dependency>
    <dependency>
      <groupId>co.cask.cdap</groupId>
      <artifactId>cdap-data-streams</artifactId>
      <version>${cdap.version}</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_2.10</artifactId>
      <version>${spark.version}</version>
      <scope>provided</scope>
      <exclusions>
        <exclusion>
          <groupId>org.slf4j</groupId>
          <artifactId>slf4j-log4j12</artifactId>
        </exclusion>
        <exclusion>
          <groupId>log4j</groupId>
          <artifactId>log4j</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.hadoop</groupId>
          <artifactId>hadoop-client</artifactId>
        </exclusion>
        <exclusion>
          <groupId>com.esotericsoftware.reflectasm</groupId>
          <artifactId>reflectasm</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.curator</groupId>
          <artifactId>curator-recipes</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.tachyonproject</groupId>
          <artifactId>tachyon-client</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.scala-lang</groupId>
          <artifactId>scala-compiler</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.eclipse.jetty.orbit</groupId>
          <artifactId>javax.servlet</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-streaming_2.10</artifactId>
      <version>${spark.version}</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-sql_2.10</artifactId>
      <version>${spark.version}</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>com.microsoft.sqlserver</groupId>
      <artifactId>mssql-jdbc</artifactId>
      <version>6.1.0.jre7</version>
    </dependency>
    <dependency>
      <groupId>com.google.guava</groupId>
      <artifactId>guava</artifactId>
      <version>13.0.1</version>
    </dependency>
    <dependency>
      <groupId>co.cask.hydrator</groupId>
      <artifactId>database-plugins</artifactId>
      <version>1.7.0-SNAPSHOT</version>
    </dependency>
    <dependency>
      <groupId>co.cask.cdap</groupId>
      <artifactId>cdap-api-spark</artifactId>
      <version>4.1.1-SNAPSHOT</version>
    </dependency>
  </dependencies>

  <build>
    <plugins>
      <plugin>
        <groupId>net.alchim31.maven</groupId>
        <artifactId>scala-maven-plugin</artifactId>
        <version>3.2.2</version>
        <configuration>
          <args>
            <arg>-target:jvm-1.7</arg>
          </args>
        </configuration>
        <executions>
          <execution>
            <id>scala-add-source</id>
            <goals>
              <goal>add-source</goal>
            </goals>
          </execution>
          <execution>
            <id>scala-compile</id>
            <!-- Needs to be before the compile phase -->
            <phase>process-resources</phase>
            <goals>
              <goal>compile</goal>
            </goals>
          </execution>
          <execution>
            <id>scala-test-compile</id>
            <!-- Needs to be before the test-compile phase -->
            <phase>process-test-resources</phase>
            <goals>
              <goal>testCompile</goal>
            </goals>
          </execution>
        </executions>
      </plugin>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-compiler-plugin</artifactId>
        <version>3.1</version>
        <configuration>
          <source>1.7</source>
          <target>1.7</target>
        </configuration>
      </plugin>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-surefire-plugin</artifactId>
        <version>2.14.1</version>
        <configuration>
          <argLine>-Xmx5000m -Djava.awt.headless=true -XX:MaxPermSize=1024m -XX:+UseConcMarkSweepGC -XX:OnOutOfMemoryError="kill -9 %p" -Djava.net.preferIPv4Stack=true</argLine>
          <reuseForks>false</reuseForks>
          <reportFormat>plain</reportFormat>
          <systemPropertyVariables>
            <java.io.tmpdir>${project.build.directory}</java.io.tmpdir>
          </systemPropertyVariables>
          <includes>
            <include>**/*TestsSuite.java</include>
            <include>**/*TestSuite.java</include>
            <include>**/Test*.java</include>
            <include>**/*Test.java</include>
            <include>**/*TestCase.java</include>
          </includes>
          <excludes>
            <exclude>**/*TestRun.java</exclude>
          </excludes>
        </configuration>
      </plugin>
      <plugin>
        <groupId>org.apache.felix</groupId>
        <artifactId>maven-bundle-plugin</artifactId>
        <version>2.5.4</version>
        <extensions>true</extensions>
        <configuration>
          <instructions>
            <Embed-Dependency>*;inline=false;scope=compile</Embed-Dependency>
            <Embed-Transitive>true</Embed-Transitive>
            <Embed-Directory>lib</Embed-Directory>
            <!--Only @Plugin classes in the export packages will be included as plugin-->
            <_exportcontents>co.cask.hydrator.sqlcdc*;com.microsoft.sqlserver.*;com.microsoft.sql.*;</_exportcontents>
          </instructions>
        </configuration>
        <executions>
          <execution>
            <phase>package</phase>
            <goals>
              <goal>bundle</goal>
            </goals>
          </execution>
        </executions>
      </plugin>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-antrun-plugin</artifactId>
        <version>1.7</version>
        <executions>
          <!-- Create the config file for artifact which can be used to deploy the artifact.
               Sets the parents field to system:cdap-etl-batch and system:cdap-etl-realtime with whatever
               version range is set in the etl.versionRange property.
               also sets a widget and doc property for each file contained in the widgets and docs directories. -->
          <execution>
            <id>create-artifact-config</id>
            <phase>prepare-package</phase>
            <configuration>
              <target>
                <script language="javascript"> <![CDATA[
                  // for some reason, project.basedir evaluates to null if we just get the property here.
                  // so we set main.basedir to project.basedir in the pom properties, then main.basedir is used here
                  // where it evaluates correctly for whatever reason
                  var baseDir = project.getProperty("main.basedir");
                  var targetDir = project.getProperty("project.build.directory");
                  var artifactId = project.getProperty("project.artifactId");
                  var version = project.getProperty("project.version");
                  var cfgFile = new java.io.File(targetDir, artifactId + "-" + version + ".json");
                  if (!cfgFile.exists()) {
                    cfgFile.createNewFile();
                  }
                  var parents = project.getProperty("app.parents").split(",");
                  var config = {
                    "parents": [ ],
                    "properties": {}
                  }
                  for (i = 0; i < parents.length; i+=2) {
                    // because name1[lo,hi],name2[lo,hi] gets split into "name1[lo", "hi]", "name2[lo", "hi]"
                    // so we have to combine them again
                    config.parents.push(parents[i] + "," + parents[i+1]);
                  }
                  // look in widgets directory for widget config for each plugin
                  var widgetsDir = new java.io.File(baseDir, project.getProperty("widgets.dir"));
                  if (widgetsDir.isDirectory()) {
                    var widgetsFiles = widgetsDir.listFiles();
                    for (i = 0; i < widgetsFiles.length; i++) {
                      var widgetsFile = widgetsFiles[i];
                      if (widgetsFile.isFile()) {
                        var propertyName = "widgets." + widgetsFile.getName();
                        // if the filename ends with .json
                        if (propertyName.indexOf(".json", propertyName.length - 5) !== -1) {
                          // strip the .json
                          propertyName = propertyName.slice(0, -5);
                          var contents = new java.lang.String(java.nio.file.Files.readAllBytes(widgetsFile.toPath()), java.nio.charset.StandardCharsets.UTF_8);
                          var contentsAsJson = JSON.parse(contents);
                          config.properties[propertyName] = JSON.stringify(contentsAsJson);
                        }
                      }
                    }
                  }
                  // look in the docs directory for docs for each plugin
                  var docsDir = new java.io.File(baseDir, project.getProperty("docs.dir"));
                  if (docsDir.isDirectory()) {
                    var docFiles = docsDir.listFiles();
                    for (i = 0; i < docFiles.length; i++) {
                      var docFile = docFiles[i];
                      if (docFile.isFile()) {
                        var propertyName = "doc." + docFile.getName();
                        // if the filename ends with .md
                        if (propertyName.indexOf(".md", propertyName.length - 3) !== -1) {
                          // strip the extension
                          propertyName = propertyName.slice(0, -3);
                          var contents = new java.lang.String(java.nio.file.Files.readAllBytes(docFile.toPath()), java.nio.charset.StandardCharsets.UTF_8);
                          config.properties[propertyName] = contents + "";
                        }
                      }
                    }
                  }
                  var fw = new java.io.BufferedWriter(new java.io.FileWriter(cfgFile.getAbsoluteFile()));
                  fw.write(JSON.stringify(config, null, 2));
                  fw.close();
                ]]></script>
              </target>
            </configuration>
            <goals>
              <goal>run</goal>
            </goals>
          </execution>
        </executions>
      </plugin>
    </plugins>
  </build>
</project>
